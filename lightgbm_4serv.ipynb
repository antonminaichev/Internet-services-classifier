{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b704a26c",
   "metadata": {},
   "source": [
    "## Классификация сервисов яндекс при помощи модели LigthGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30f50f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas version:  1.4.4\n",
      "lightgbm version:  4.1.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sys  \n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import (confusion_matrix, accuracy_score, ConfusionMatrixDisplay)\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "print(\"Pandas version: \", pd.__version__)\n",
    "print(\"lightgbm version: \", lgb.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4015f114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_final:  (8375, 40)\n"
     ]
    }
   ],
   "source": [
    "current_path = ''\n",
    "\n",
    "\n",
    "df_final_filename = f'data/df_final_4serv.csv'\n",
    "\n",
    "dfFinal = pd.read_csv(df_final_filename)\n",
    "\n",
    "print('df_final: ', dfFinal.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d5c70fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFinal.dropna(axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e458552b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['proto',\n",
       " 'packets_count',\n",
       " 'min_fiat',\n",
       " 'min_biat',\n",
       " 'flow_packets_per_second',\n",
       " 'f_min_pkt_size',\n",
       " 'b_min_pkt_size',\n",
       " 'diag_step_fiat',\n",
       " 'diag_step_biat',\n",
       " 'diag_steps',\n",
       " 'tcp_syn_count',\n",
       " 'tcp_rst_count',\n",
       " 'tcp_fin_count',\n",
       " 'tcp_urg_count',\n",
       " 'tcp_retr_count',\n",
       " 'pktiat_0',\n",
       " 'pktiat_1',\n",
       " 'pktiat_2',\n",
       " 'pktlen_1',\n",
       " 'type']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfFinal.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e1ac69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dfFinal['type']\n",
    "drop_col = ['type','proto','diag_step_fiat','diag_step_biat','diag_steps']\n",
    "X  = dfFinal.drop(columns=drop_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb688562",
   "metadata": {},
   "source": [
    "#### Разобьем данные на подопытные и проверочные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a11ff426",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                        test_size=0.3,\n",
    "                                                        random_state=42,\n",
    "                                                        stratify=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9c45d0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['packets_count',\n",
       " 'min_fiat',\n",
       " 'min_biat',\n",
       " 'flow_packets_per_second',\n",
       " 'f_min_pkt_size',\n",
       " 'b_min_pkt_size',\n",
       " 'tcp_syn_count',\n",
       " 'tcp_rst_count',\n",
       " 'tcp_fin_count',\n",
       " 'tcp_urg_count',\n",
       " 'tcp_retr_count',\n",
       " 'pktiat_0',\n",
       " 'pktiat_1',\n",
       " 'pktiat_2',\n",
       " 'pktlen_1']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ccd3a5a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "67e4eba5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fa7d87dc",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "293c8a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = lgb.LGBMClassifier(objective='multiclass', \n",
    "                               boosting_type = 'gbdt', \n",
    "                               num_class = '3',\n",
    "                               n_estimators = 1, \n",
    "                               num_trees = 1,\n",
    "                               min_child_samples = 2,\n",
    "                               class_weight = 'balanced')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b404ed0",
   "metadata": {},
   "source": [
    "##### ...со следующим набором гиперпараметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d5ad2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'max_depth': [3,4,5],\n",
    "    'num_leaves': [10,20,30],\n",
    "    'learning_rate': [0.1, 0.5, 1],\n",
    "    'feature_fraction': [0.3, 0.5, 1],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6951e2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(estimator, param_grid=parameters, scoring='accuracy', cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88bc228d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000165 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1395\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000188 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1400\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000154 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1398\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000140 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1395\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000146 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1400\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000178 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1398\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000145 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1395\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000150 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1400\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000161 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1398\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000167 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1395\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000165 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1400\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000168 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1398\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000175 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1395\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000187 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1400\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000173 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1398\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000185 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1395\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000175 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1400\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000181 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1398\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000169 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1395\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000347 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1400\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000409 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1398\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000229 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1395\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000474 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1400\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000197 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1398\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000209 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1395\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000247 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1400\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000496 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1398\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000180 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1395\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000178 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1400\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000179 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1398\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000212 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1395\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000176 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1400\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000172 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1398\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000175 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1395\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000241 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1400\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000189 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1398\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000208 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1395\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000188 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1400\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000176 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1398\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000183 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1395\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000178 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1400\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000170 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1398\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000184 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1395\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000190 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1400\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000186 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1398\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000209 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1395\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000261 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1400\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000182 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1398\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000184 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1395\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000266 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1400\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000169 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1398\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000261 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1395\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000215 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1400\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000236 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1398\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000184 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1395\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000220 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1400\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000251 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1398\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000179 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1395\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000199 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1400\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000184 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1398\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000181 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1395\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000227 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1400\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000180 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1398\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000174 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1395\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000216 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1400\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000219 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1398\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000241 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1395\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000430 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1400\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000292 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1398\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000290 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1395\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000181 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1400\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000182 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1398\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000201 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1395\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000211 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1400\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000178 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1398\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000503 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1395\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000233 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1400\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000228 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1398\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000177 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1395\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000218 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1400\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000182 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1398\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000498 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1395\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000198 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1400\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000502 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1398\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000186 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1395\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000197 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1400\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000467 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1398\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000193 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1395\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000198 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1400\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000254 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1398\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000342 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1395\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000434 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1400\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000473 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1398\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000507 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1395\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000192 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1400\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000542 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1398\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000194 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1395\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000195 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1400\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000259 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1398\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000274 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1395\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000256 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1400\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000519 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1398\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000469 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1395\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000466 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1400\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000194 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1398\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000189 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1395\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000544 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1400\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000664 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1398\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000359 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1395\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000285 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1400\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000675 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1398\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000192 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1395\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000193 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1400\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000466 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1398\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000470 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1395\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000544 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1400\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000595 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1398\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000228 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1395\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000227 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1400\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000534 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1398\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000541 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1395\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000525 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1400\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000585 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1398\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000227 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1395\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000201 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1400\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000201 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1398\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000193 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1395\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000221 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1400\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000523 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1398\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000234 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1395\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000192 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1400\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000189 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1398\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000197 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1395\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000501 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1400\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000227 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1398\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000257 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1395\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000546 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1400\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000553 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1398\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000305 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1395\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000194 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1400\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000195 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1398\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000194 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1395\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000193 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1400\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000217 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1398\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000525 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1395\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000253 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1400\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000589 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1398\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000545 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1395\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000493 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1400\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000196 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1398\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000553 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1395\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000507 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1400\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000203 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1398\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000192 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1395\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000528 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1400\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000227 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1398\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000518 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1395\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000194 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1400\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000445 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1398\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000196 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1395\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000196 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1400\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000264 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1398\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000266 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1395\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000583 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1400\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000587 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1398\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000386 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1395\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000720 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1400\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000332 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1398\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000534 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1395\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000589 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1400\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000505 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1398\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000216 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1395\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000570 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1400\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000673 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1398\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000689 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1395\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000465 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1400\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000470 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1398\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000549 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1395\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000561 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1400\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000491 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1398\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000496 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1395\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000305 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1400\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000610 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1398\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000522 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1395\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000553 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1400\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000584 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1398\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000516 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1395\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000511 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1400\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000531 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1398\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000483 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1395\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000579 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1400\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000648 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1398\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000597 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1395\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000503 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1400\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000592 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1398\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000625 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1395\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000531 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1400\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000506 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1398\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000486 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1395\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000531 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1400\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000558 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1398\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000639 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1395\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000520 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1400\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000589 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1398\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000527 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1395\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000272 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1400\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000596 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1398\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000225 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1395\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000215 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1400\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000518 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1398\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000291 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1395\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000274 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1400\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000491 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1398\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000517 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1395\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000500 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1400\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000516 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1398\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000287 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1395\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000476 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1400\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000493 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1398\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000567 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1395\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000222 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1400\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000803 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1398\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000511 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1395\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000519 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1400\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000579 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1398\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000501 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1395\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000535 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1400\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000630 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1398\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001074 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1395\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000369 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1400\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000779 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1398\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000483 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1395\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000508 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1400\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000634 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1398\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000643 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1395\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000596 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1400\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000256 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1398\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000288 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1395\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000772 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1400\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000569 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1398\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000727 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1395\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000348 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1400\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000222 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1398\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000394 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1428\n",
      "[LightGBM] [Info] Number of data points in the train set: 5862, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=LGBMClassifier(class_weight='balanced',\n",
       "                                      min_child_samples=2, n_estimators=1,\n",
       "                                      num_class='3', num_trees=1,\n",
       "                                      objective='multiclass'),\n",
       "             param_grid={'feature_fraction': [0.3, 0.5, 1],\n",
       "                         'learning_rate': [0.1, 0.5, 1], 'max_depth': [3, 4, 5],\n",
       "                         'num_leaves': [10, 20, 30]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2bb55da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(class_weight='balanced', feature_fraction=1, max_depth=5,\n",
       "               min_child_samples=2, n_estimators=1, num_class='3',\n",
       "               num_leaves=20, num_trees=1, objective='multiclass')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9353ab07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n"
     ]
    }
   ],
   "source": [
    "predictions_LGB = grid_search.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d5458b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "0.9514524472741743\n"
     ]
    }
   ],
   "source": [
    "print(grid_search.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e8936bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importances:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "################################################################################\n",
      "Confusion Matrix:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "################################################################################\n",
      "Classification Report:\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       495\n",
      "           1       0.95      0.84      0.89       499\n",
      "           2       0.82      0.95      0.88       405\n",
      "           3       1.00      1.00      1.00      1114\n",
      "\n",
      "    accuracy                           0.95      2513\n",
      "   macro avg       0.93      0.94      0.93      2513\n",
      "weighted avg       0.95      0.95      0.95      2513\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feature_importances = np.zeros(X.shape[1])\n",
    "\n",
    "print('Feature importances:')\n",
    "lgb.plot_importance(grid_search.best_estimator_)\n",
    "plt.show()\n",
    "\n",
    "print('\\n' + '#' * 80)\n",
    "print('Confusion Matrix:')\n",
    "    # functions.plot_confusion_matrix(valid_y, predictions_LGB.round(), \"Analysis\",\n",
    "    #                                 index=[\"Std SSH\", \"Obf SSH\"], columns=[\"Std SSH\", \"Obf SSH\"])\n",
    "    # metrics.confusion_matrix(model, valid_features, valid_y, cmap='Blues_r')\n",
    "cm = confusion_matrix(y_test, predictions_LGB, labels=grid_search.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"video\", \"music\", \"disk\",'noserv'])\n",
    "disp.plot() #cmap='Blues_r')\n",
    "plt.show()\n",
    "    \n",
    "print('\\n' + '#' * 80)\n",
    "print('Classification Report:')\n",
    "print(metrics.classification_report(y_test, grid_search.predict(X_test)))\n",
    "plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ab8f4a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>pktiat_2</td>\n",
       "      <td>10.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>min_fiat</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>pktiat_1</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>min_biat</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>flow_packets_per_second</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>tcp_retr_count</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f_min_pkt_size</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>packets_count</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>b_min_pkt_size</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tcp_syn_count</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    feature  importance\n",
       "13                 pktiat_2        10.5\n",
       "1                  min_fiat         7.0\n",
       "12                 pktiat_1         6.5\n",
       "2                  min_biat         3.5\n",
       "3   flow_packets_per_second         3.5\n",
       "10           tcp_retr_count         1.5\n",
       "4            f_min_pkt_size         0.5\n",
       "0             packets_count         0.0\n",
       "5            b_min_pkt_size         0.0\n",
       "6             tcp_syn_count         0.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make sure to average feature importances! \n",
    "feature_importances = grid_search.best_estimator_.feature_importances_ / 2\n",
    "feature_importances = pd.DataFrame({'feature': list(X.columns),\n",
    "                                    'importance': feature_importances}\n",
    "                                  ).sort_values('importance', ascending = False)\n",
    "\n",
    "feature_importances.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f0cb1c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "packets_count              10.000000\n",
      "min_fiat                    0.000691\n",
      "min_biat                    0.000010\n",
      "flow_packets_per_second     1.000000\n",
      "f_min_pkt_size             66.000000\n",
      "b_min_pkt_size             66.000000\n",
      "tcp_syn_count               0.000000\n",
      "tcp_rst_count               0.000000\n",
      "tcp_fin_count               0.000000\n",
      "tcp_urg_count               0.000000\n",
      "tcp_retr_count             10.000000\n",
      "pktiat_0                    0.000000\n",
      "pktiat_1                    0.007042\n",
      "pktiat_2                    0.000323\n",
      "pktlen_1                   66.000000\n",
      "Name: 1, dtype: float64\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(X_train.loc[1])\n",
    "print(y_train.loc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7758d697",
   "metadata": {},
   "outputs": [
    {
     "ename": "ExecutableNotFound",
     "evalue": "failed to execute WindowsPath('dot'), make sure the Graphviz executables are on your systems' PATH",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\graphviz\\backend\\execute.py\u001b[0m in \u001b[0;36mrun_check\u001b[1;34m(cmd, input_lines, encoding, quiet, **kwargs)\u001b[0m\n\u001b[0;32m     78\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'stdout'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'stderr'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m             \u001b[0mproc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_run_input_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_lines\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\graphviz\\backend\\execute.py\u001b[0m in \u001b[0;36m_run_input_lines\u001b[1;34m(cmd, input_lines, kwargs)\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_run_input_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_lines\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m     \u001b[0mpopen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstdin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask)\u001b[0m\n\u001b[0;32m    950\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 951\u001b[1;33m             self._execute_child(args, executable, preexec_fn, close_fds,\n\u001b[0m\u001b[0;32m    952\u001b[0m                                 \u001b[0mpass_fds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcwd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_gid, unused_gids, unused_uid, unused_umask, unused_start_new_session)\u001b[0m\n\u001b[0;32m   1419\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1420\u001b[1;33m                 hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n\u001b[0m\u001b[0;32m   1421\u001b[0m                                          \u001b[1;31m# no special security\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] Не удается найти указанный файл",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mExecutableNotFound\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19028\\3541053158.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'split_gain'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'internal_value'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'internal_count'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'internal_weight'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'leaf_count'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'leaf_weight'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'data_percentage'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mlgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot_tree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtree_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m40\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_info\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mexample_case\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\lightgbm\\plotting.py\u001b[0m in \u001b[0;36mplot_tree\u001b[1;34m(booster, ax, tree_index, figsize, dpi, show_info, precision, orientation, example_case, **kwargs)\u001b[0m\n\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m     \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 822\u001b[1;33m     \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpipe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'png'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    823\u001b[0m     \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    824\u001b[0m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\graphviz\\piping.py\u001b[0m in \u001b[0;36mpipe\u001b[1;34m(self, format, renderer, formatter, neato_no_op, quiet, engine, encoding)\u001b[0m\n\u001b[0;32m    102\u001b[0m             \u001b[1;34m'<?xml version='\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m         \"\"\"\n\u001b[1;32m--> 104\u001b[1;33m         return self._pipe_legacy(format,\n\u001b[0m\u001b[0;32m    105\u001b[0m                                  \u001b[0mrenderer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m                                  \u001b[0mformatter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mformatter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\graphviz\\_tools.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    169\u001b[0m                               category=category)\n\u001b[0;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 171\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\graphviz\\piping.py\u001b[0m in \u001b[0;36m_pipe_legacy\u001b[1;34m(self, format, renderer, formatter, neato_no_op, quiet, engine, encoding)\u001b[0m\n\u001b[0;32m    119\u001b[0m                      \u001b[0mengine\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtyping\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m                      encoding: typing.Optional[str] = None) -> typing.Union[bytes, str]:\n\u001b[1;32m--> 121\u001b[1;33m         return self._pipe_future(format,\n\u001b[0m\u001b[0;32m    122\u001b[0m                                  \u001b[0mrenderer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m                                  \u001b[0mformatter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mformatter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\graphviz\\piping.py\u001b[0m in \u001b[0;36m_pipe_future\u001b[1;34m(self, format, renderer, formatter, neato_no_op, quiet, engine, encoding)\u001b[0m\n\u001b[0;32m    159\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mraw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 161\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pipe_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_encoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\graphviz\\backend\\piping.py\u001b[0m in \u001b[0;36mpipe_lines\u001b[1;34m(engine, format, input_lines, input_encoding, renderer, formatter, neato_no_op, quiet)\u001b[0m\n\u001b[0;32m    159\u001b[0m     \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'input_lines'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_encoding\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minput_lines\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 161\u001b[1;33m     \u001b[0mproc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecute\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_check\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcapture_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquiet\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mquiet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    162\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mproc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\graphviz\\backend\\execute.py\u001b[0m in \u001b[0;36mrun_check\u001b[1;34m(cmd, input_lines, encoding, quiet, **kwargs)\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrno\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0merrno\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mENOENT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mExecutableNotFound\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m         \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mExecutableNotFound\u001b[0m: failed to execute WindowsPath('dot'), make sure the Graphviz executables are on your systems' PATH"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 3000x4000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "info = ['split_gain', 'internal_value', 'internal_count', 'internal_weight', 'leaf_count', 'leaf_weight', 'data_percentage']\n",
    "lgb.plot_tree(grid_search.best_estimator_, tree_index=0, figsize=(30,40), show_info=info,example_case = X_train.loc[[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eee0e328",
   "metadata": {},
   "outputs": [
    {
     "ename": "ExecutableNotFound",
     "evalue": "failed to execute WindowsPath('dot'), make sure the Graphviz executables are on your systems' PATH",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\graphviz\\backend\\execute.py\u001b[0m in \u001b[0;36mrun_check\u001b[1;34m(cmd, input_lines, encoding, quiet, **kwargs)\u001b[0m\n\u001b[0;32m     78\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'stdout'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'stderr'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m             \u001b[0mproc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_run_input_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_lines\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\graphviz\\backend\\execute.py\u001b[0m in \u001b[0;36m_run_input_lines\u001b[1;34m(cmd, input_lines, kwargs)\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_run_input_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_lines\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m     \u001b[0mpopen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstdin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask)\u001b[0m\n\u001b[0;32m    950\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 951\u001b[1;33m             self._execute_child(args, executable, preexec_fn, close_fds,\n\u001b[0m\u001b[0;32m    952\u001b[0m                                 \u001b[0mpass_fds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcwd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_gid, unused_gids, unused_uid, unused_umask, unused_start_new_session)\u001b[0m\n\u001b[0;32m   1419\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1420\u001b[1;33m                 hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n\u001b[0m\u001b[0;32m   1421\u001b[0m                                          \u001b[1;31m# no special security\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] Не удается найти указанный файл",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mExecutableNotFound\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19028\\336374839.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot_tree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtree_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m40\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_info\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mexample_case\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\lightgbm\\plotting.py\u001b[0m in \u001b[0;36mplot_tree\u001b[1;34m(booster, ax, tree_index, figsize, dpi, show_info, precision, orientation, example_case, **kwargs)\u001b[0m\n\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m     \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 822\u001b[1;33m     \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpipe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'png'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    823\u001b[0m     \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    824\u001b[0m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\graphviz\\piping.py\u001b[0m in \u001b[0;36mpipe\u001b[1;34m(self, format, renderer, formatter, neato_no_op, quiet, engine, encoding)\u001b[0m\n\u001b[0;32m    102\u001b[0m             \u001b[1;34m'<?xml version='\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m         \"\"\"\n\u001b[1;32m--> 104\u001b[1;33m         return self._pipe_legacy(format,\n\u001b[0m\u001b[0;32m    105\u001b[0m                                  \u001b[0mrenderer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m                                  \u001b[0mformatter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mformatter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\graphviz\\_tools.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    169\u001b[0m                               category=category)\n\u001b[0;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 171\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\graphviz\\piping.py\u001b[0m in \u001b[0;36m_pipe_legacy\u001b[1;34m(self, format, renderer, formatter, neato_no_op, quiet, engine, encoding)\u001b[0m\n\u001b[0;32m    119\u001b[0m                      \u001b[0mengine\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtyping\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m                      encoding: typing.Optional[str] = None) -> typing.Union[bytes, str]:\n\u001b[1;32m--> 121\u001b[1;33m         return self._pipe_future(format,\n\u001b[0m\u001b[0;32m    122\u001b[0m                                  \u001b[0mrenderer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m                                  \u001b[0mformatter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mformatter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\graphviz\\piping.py\u001b[0m in \u001b[0;36m_pipe_future\u001b[1;34m(self, format, renderer, formatter, neato_no_op, quiet, engine, encoding)\u001b[0m\n\u001b[0;32m    159\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mraw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 161\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pipe_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_encoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\graphviz\\backend\\piping.py\u001b[0m in \u001b[0;36mpipe_lines\u001b[1;34m(engine, format, input_lines, input_encoding, renderer, formatter, neato_no_op, quiet)\u001b[0m\n\u001b[0;32m    159\u001b[0m     \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'input_lines'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_encoding\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minput_lines\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 161\u001b[1;33m     \u001b[0mproc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecute\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_check\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcapture_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquiet\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mquiet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    162\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mproc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\graphviz\\backend\\execute.py\u001b[0m in \u001b[0;36mrun_check\u001b[1;34m(cmd, input_lines, encoding, quiet, **kwargs)\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrno\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0merrno\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mENOENT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mExecutableNotFound\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m         \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mExecutableNotFound\u001b[0m: failed to execute WindowsPath('dot'), make sure the Graphviz executables are on your systems' PATH"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 3000x4000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "lgb.plot_tree(grid_search.best_estimator_, tree_index=1, figsize=(30,40), show_info=info,example_case = X_train.loc[[1]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "763524f8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ExecutableNotFound",
     "evalue": "failed to execute WindowsPath('dot'), make sure the Graphviz executables are on your systems' PATH",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\graphviz\\backend\\execute.py\u001b[0m in \u001b[0;36mrun_check\u001b[1;34m(cmd, input_lines, encoding, quiet, **kwargs)\u001b[0m\n\u001b[0;32m     78\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'stdout'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'stderr'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m             \u001b[0mproc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_run_input_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_lines\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\graphviz\\backend\\execute.py\u001b[0m in \u001b[0;36m_run_input_lines\u001b[1;34m(cmd, input_lines, kwargs)\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_run_input_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_lines\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m     \u001b[0mpopen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstdin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask)\u001b[0m\n\u001b[0;32m    950\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 951\u001b[1;33m             self._execute_child(args, executable, preexec_fn, close_fds,\n\u001b[0m\u001b[0;32m    952\u001b[0m                                 \u001b[0mpass_fds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcwd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_gid, unused_gids, unused_uid, unused_umask, unused_start_new_session)\u001b[0m\n\u001b[0;32m   1419\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1420\u001b[1;33m                 hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n\u001b[0m\u001b[0;32m   1421\u001b[0m                                          \u001b[1;31m# no special security\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] Не удается найти указанный файл",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mExecutableNotFound\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19028\\107032411.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot_tree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtree_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m40\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_info\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mexample_case\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\lightgbm\\plotting.py\u001b[0m in \u001b[0;36mplot_tree\u001b[1;34m(booster, ax, tree_index, figsize, dpi, show_info, precision, orientation, example_case, **kwargs)\u001b[0m\n\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m     \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 822\u001b[1;33m     \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpipe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'png'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    823\u001b[0m     \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    824\u001b[0m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\graphviz\\piping.py\u001b[0m in \u001b[0;36mpipe\u001b[1;34m(self, format, renderer, formatter, neato_no_op, quiet, engine, encoding)\u001b[0m\n\u001b[0;32m    102\u001b[0m             \u001b[1;34m'<?xml version='\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m         \"\"\"\n\u001b[1;32m--> 104\u001b[1;33m         return self._pipe_legacy(format,\n\u001b[0m\u001b[0;32m    105\u001b[0m                                  \u001b[0mrenderer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m                                  \u001b[0mformatter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mformatter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\graphviz\\_tools.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    169\u001b[0m                               category=category)\n\u001b[0;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 171\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\graphviz\\piping.py\u001b[0m in \u001b[0;36m_pipe_legacy\u001b[1;34m(self, format, renderer, formatter, neato_no_op, quiet, engine, encoding)\u001b[0m\n\u001b[0;32m    119\u001b[0m                      \u001b[0mengine\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtyping\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m                      encoding: typing.Optional[str] = None) -> typing.Union[bytes, str]:\n\u001b[1;32m--> 121\u001b[1;33m         return self._pipe_future(format,\n\u001b[0m\u001b[0;32m    122\u001b[0m                                  \u001b[0mrenderer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m                                  \u001b[0mformatter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mformatter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\graphviz\\piping.py\u001b[0m in \u001b[0;36m_pipe_future\u001b[1;34m(self, format, renderer, formatter, neato_no_op, quiet, engine, encoding)\u001b[0m\n\u001b[0;32m    159\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mraw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 161\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pipe_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_encoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\graphviz\\backend\\piping.py\u001b[0m in \u001b[0;36mpipe_lines\u001b[1;34m(engine, format, input_lines, input_encoding, renderer, formatter, neato_no_op, quiet)\u001b[0m\n\u001b[0;32m    159\u001b[0m     \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'input_lines'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_encoding\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minput_lines\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 161\u001b[1;33m     \u001b[0mproc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecute\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_check\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcapture_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquiet\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mquiet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    162\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mproc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\graphviz\\backend\\execute.py\u001b[0m in \u001b[0;36mrun_check\u001b[1;34m(cmd, input_lines, encoding, quiet, **kwargs)\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrno\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0merrno\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mENOENT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mExecutableNotFound\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m         \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mExecutableNotFound\u001b[0m: failed to execute WindowsPath('dot'), make sure the Graphviz executables are on your systems' PATH"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 3000x4000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lgb.plot_tree(grid_search.best_estimator_, tree_index=2, figsize=(30,40), show_info=info,example_case = X_train.loc[[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bbc33137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tree_index</th>\n",
       "      <th>node_depth</th>\n",
       "      <th>node_index</th>\n",
       "      <th>left_child</th>\n",
       "      <th>right_child</th>\n",
       "      <th>parent_index</th>\n",
       "      <th>split_feature</th>\n",
       "      <th>split_gain</th>\n",
       "      <th>threshold</th>\n",
       "      <th>decision_type</th>\n",
       "      <th>missing_direction</th>\n",
       "      <th>missing_type</th>\n",
       "      <th>value</th>\n",
       "      <th>weight</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0-S0</td>\n",
       "      <td>0-S1</td>\n",
       "      <td>0-S4</td>\n",
       "      <td>None</td>\n",
       "      <td>pktiat_1</td>\n",
       "      <td>3704.260010</td>\n",
       "      <td>0.004432</td>\n",
       "      <td>&lt;=</td>\n",
       "      <td>left</td>\n",
       "      <td>None</td>\n",
       "      <td>-1.386290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0-S1</td>\n",
       "      <td>0-S2</td>\n",
       "      <td>0-S15</td>\n",
       "      <td>0-S0</td>\n",
       "      <td>flow_packets_per_second</td>\n",
       "      <td>384.343994</td>\n",
       "      <td>0.666800</td>\n",
       "      <td>&lt;=</td>\n",
       "      <td>left</td>\n",
       "      <td>None</td>\n",
       "      <td>-1.120310</td>\n",
       "      <td>385.774000</td>\n",
       "      <td>1280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0-S2</td>\n",
       "      <td>0-S17</td>\n",
       "      <td>0-S3</td>\n",
       "      <td>0-S1</td>\n",
       "      <td>pktiat_2</td>\n",
       "      <td>9.343800</td>\n",
       "      <td>0.000410</td>\n",
       "      <td>&lt;=</td>\n",
       "      <td>left</td>\n",
       "      <td>None</td>\n",
       "      <td>-1.092730</td>\n",
       "      <td>358.404000</td>\n",
       "      <td>1095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0-S17</td>\n",
       "      <td>0-S18</td>\n",
       "      <td>0-L18</td>\n",
       "      <td>0-S2</td>\n",
       "      <td>pktiat_2</td>\n",
       "      <td>0.466560</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>&lt;=</td>\n",
       "      <td>left</td>\n",
       "      <td>None</td>\n",
       "      <td>-1.087540</td>\n",
       "      <td>324.864000</td>\n",
       "      <td>993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0-S18</td>\n",
       "      <td>0-L0</td>\n",
       "      <td>0-L19</td>\n",
       "      <td>0-S17</td>\n",
       "      <td>min_fiat</td>\n",
       "      <td>2.201710</td>\n",
       "      <td>0.000330</td>\n",
       "      <td>&lt;=</td>\n",
       "      <td>left</td>\n",
       "      <td>None</td>\n",
       "      <td>-1.123320</td>\n",
       "      <td>3.604880</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3-L1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>3-S4</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-1.486294</td>\n",
       "      <td>189.102427</td>\n",
       "      <td>578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3-L5</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>3-S4</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-1.486294</td>\n",
       "      <td>909.341617</td>\n",
       "      <td>2714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3-S2</td>\n",
       "      <td>3-L2</td>\n",
       "      <td>3-L3</td>\n",
       "      <td>3-S1</td>\n",
       "      <td>pktiat_1</td>\n",
       "      <td>3.217340</td>\n",
       "      <td>0.061464</td>\n",
       "      <td>&lt;=</td>\n",
       "      <td>left</td>\n",
       "      <td>None</td>\n",
       "      <td>-1.368180</td>\n",
       "      <td>0.966333</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3-L2</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>3-S2</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-1.086294</td>\n",
       "      <td>0.285339</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3-L3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>3-S2</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-1.486294</td>\n",
       "      <td>0.680994</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>136 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     tree_index  node_depth node_index left_child right_child parent_index  \\\n",
       "0             0           1       0-S0       0-S1        0-S4         None   \n",
       "1             0           2       0-S1       0-S2       0-S15         0-S0   \n",
       "2             0           3       0-S2      0-S17        0-S3         0-S1   \n",
       "3             0           4      0-S17      0-S18       0-L18         0-S2   \n",
       "4             0           5      0-S18       0-L0       0-L19        0-S17   \n",
       "..          ...         ...        ...        ...         ...          ...   \n",
       "131           3           4       3-L1       None        None         3-S4   \n",
       "132           3           4       3-L5       None        None         3-S4   \n",
       "133           3           3       3-S2       3-L2        3-L3         3-S1   \n",
       "134           3           4       3-L2       None        None         3-S2   \n",
       "135           3           4       3-L3       None        None         3-S2   \n",
       "\n",
       "               split_feature   split_gain  threshold decision_type  \\\n",
       "0                   pktiat_1  3704.260010   0.004432            <=   \n",
       "1    flow_packets_per_second   384.343994   0.666800            <=   \n",
       "2                   pktiat_2     9.343800   0.000410            <=   \n",
       "3                   pktiat_2     0.466560   0.000023            <=   \n",
       "4                   min_fiat     2.201710   0.000330            <=   \n",
       "..                       ...          ...        ...           ...   \n",
       "131                     None          NaN        NaN          None   \n",
       "132                     None          NaN        NaN          None   \n",
       "133                 pktiat_1     3.217340   0.061464            <=   \n",
       "134                     None          NaN        NaN          None   \n",
       "135                     None          NaN        NaN          None   \n",
       "\n",
       "    missing_direction missing_type     value      weight  count  \n",
       "0                left         None -1.386290    0.000000   5862  \n",
       "1                left         None -1.120310  385.774000   1280  \n",
       "2                left         None -1.092730  358.404000   1095  \n",
       "3                left         None -1.087540  324.864000    993  \n",
       "4                left         None -1.123320    3.604880     11  \n",
       "..                ...          ...       ...         ...    ...  \n",
       "131              None         None -1.486294  189.102427    578  \n",
       "132              None         None -1.486294  909.341617   2714  \n",
       "133              left         None -1.368180    0.966333      4  \n",
       "134              None         None -1.086294    0.285339      2  \n",
       "135              None         None -1.486294    0.680994      2  \n",
       "\n",
       "[136 rows x 15 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_df = grid_search.best_estimator_.booster_.trees_to_dataframe()\n",
    "print(tree_df.tree_index.max())\n",
    "grid_search.best_estimator_.booster_.trees_to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6689470b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['packets_count',\n",
       " 'min_fiat',\n",
       " 'min_biat',\n",
       " 'flow_packets_per_second',\n",
       " 'f_min_pkt_size',\n",
       " 'b_min_pkt_size',\n",
       " 'tcp_syn_count',\n",
       " 'tcp_rst_count',\n",
       " 'tcp_fin_count',\n",
       " 'tcp_urg_count',\n",
       " 'tcp_retr_count',\n",
       " 'pktiat_0',\n",
       " 'pktiat_1',\n",
       " 'pktiat_2',\n",
       " 'pktlen_1']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "48f8168e",
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: '/model_lightgbm.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19028\\4055981367.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mjoblib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mf'{current_path}/model_lightgbm.pkl'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\numpy_pickle.py\u001b[0m in \u001b[0;36mdump\u001b[1;34m(value, filename, compress, protocol, cache_size)\u001b[0m\n\u001b[0;32m    479\u001b[0m             \u001b[0mNumpyPickler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    480\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mis_filename\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 481\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    482\u001b[0m             \u001b[0mNumpyPickler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    483\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: '/model_lightgbm.pkl'"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(grid_search.best_estimator_, f'{current_path}/model_lightgbm.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7ebc9f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000206 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1428\n",
      "[LightGBM] [Info] Number of data points in the train set: 5862, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000182 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1420\n",
      "[LightGBM] [Info] Number of data points in the train set: 5862, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000186 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1398\n",
      "[LightGBM] [Info] Number of data points in the train set: 5862, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000173 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1395\n",
      "[LightGBM] [Info] Number of data points in the train set: 5862, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000156 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1391\n",
      "[LightGBM] [Info] Number of data points in the train set: 5862, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000068 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1385\n",
      "[LightGBM] [Info] Number of data points in the train set: 5862, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000069 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1385\n",
      "[LightGBM] [Info] Number of data points in the train set: 5862, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000169 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1385\n",
      "[LightGBM] [Info] Number of data points in the train set: 5862, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000132 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1306\n",
      "[LightGBM] [Info] Number of data points in the train set: 5862, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000148 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1283\n",
      "[LightGBM] [Info] Number of data points in the train set: 5862, number of used features: 6\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000104 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Number of data points in the train set: 5862, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000106 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1020\n",
      "[LightGBM] [Info] Number of data points in the train set: 5862, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "model_for_rfe = grid_search.best_estimator_\n",
    "\n",
    "rfe = RFE(model_for_rfe, n_features_to_select=4, step=1)\n",
    "X_train_rfe = X_train\n",
    "y_train_rfe = y_train\n",
    "fit = rfe.fit(X_train_rfe,y_train_rfe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "68abd669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Число признаков: 4\n",
      "Отобранные признаки: [False  True False  True False False False False False False False False\n",
      "  True  True False]\n",
      "Ранг признаков: [12  1  2  1  4 11 10  9  8  7  3  6  1  1  5]\n"
     ]
    }
   ],
   "source": [
    "print((\"Число признаков: %d\") %fit.n_features_)\n",
    "print((\"Отобранные признаки: %s\") %fit.support_)\n",
    "print((\"Ранг признаков: %s\") %fit.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e140410c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['min_fiat' 'flow_packets_per_second' 'pktiat_1' 'pktiat_2']\n"
     ]
    }
   ],
   "source": [
    "feature_names_rfe = fit.get_feature_names_out()\n",
    "print(feature_names_rfe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6848c56d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b3c113c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "0.9534421010744131\n"
     ]
    }
   ],
   "source": [
    "print(fit.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fed3da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eaee3ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFinal_new = dfFinal[feature_names_rfe]\n",
    "y = dfFinal['type']\n",
    "\n",
    "X  = dfFinal_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed15cef",
   "metadata": {},
   "source": [
    "#### Разобьем данные на подопытные и проверочные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f935779b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                        test_size=0.3,\n",
    "                                                        random_state=42,\n",
    "                                                        stratify=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ab769363",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8375, 4)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24c45a8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3abc2a18",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c73abc48",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0d88a248",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = lgb.LGBMClassifier(objective='multiclass', \n",
    "                               boosting_type = 'gbdt', \n",
    "                               num_class = '3',\n",
    "                               n_estimators = 100, \n",
    "                               class_weight = 'balanced')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4321452f",
   "metadata": {},
   "source": [
    "##### ...со следующим набором гиперпараметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7f2da23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'max_depth': [4],\n",
    "    'num_leaves': [20],\n",
    "    'min_child_samples': [19],\n",
    "    'min_child_weight': [0.002],\n",
    "    'feature_fraction': [0.6],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2b5f3014",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(estimator, param_grid=parameters, scoring='accuracy', cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "35fb8c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000077 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1020\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000071 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1020\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000168 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1020\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000145 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1020\n",
      "[LightGBM] [Info] Number of data points in the train set: 5862, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=LGBMClassifier(class_weight='balanced', num_class='3',\n",
       "                                      objective='multiclass'),\n",
       "             param_grid={'feature_fraction': [0.6], 'max_depth': [4],\n",
       "                         'min_child_samples': [19], 'min_child_weight': [0.002],\n",
       "                         'num_leaves': [20]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f838882a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(class_weight='balanced', feature_fraction=0.6, max_depth=4,\n",
       "               min_child_samples=19, min_child_weight=0.002, num_class='3',\n",
       "               num_leaves=20, objective='multiclass')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3fa4800a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "0.9538400318344608\n"
     ]
    }
   ],
   "source": [
    "predictions_LGB = grid_search.predict(X_test)\n",
    "print(grid_search.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7f22bb5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importances:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "################################################################################\n",
      "Confusion Matrix:\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The number of FixedLocator locations (4), usually from a call to set_ticks, does not match the number of ticklabels (3).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19028\\669805817.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mcm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictions_LGB\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mdisp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mConfusionMatrixDisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdisplay_labels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"video\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"music\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"disk\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mdisp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#cmap='Blues_r')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_plot\\confusion_matrix.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(self, include_values, cmap, xticks_rotation, values_format, ax, colorbar)\u001b[0m\n\u001b[0;32m    161\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcolorbar\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m             \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolorbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mim_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m         ax.set(\n\u001b[0m\u001b[0;32m    164\u001b[0m             \u001b[0mxticks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m             \u001b[0myticks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\artist.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    114\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m         \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mArtist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m         \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"set\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__qualname__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf\"{cls.__qualname__}.set\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\artist.py\u001b[0m in \u001b[0;36mset\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m   1162\u001b[0m         \u001b[1;31m# module.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1163\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1164\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1165\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1166\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mcontextlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontextmanager\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\artist.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, props)\u001b[0m\n\u001b[0;32m   1064\u001b[0m                         raise AttributeError(f\"{type(self).__name__!r} object \"\n\u001b[0;32m   1065\u001b[0m                                              f\"has no property {k!r}\")\n\u001b[1;32m-> 1066\u001b[1;33m                     \u001b[0mret\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1067\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1068\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpchanged\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mget_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mowner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__module__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\axis.py\u001b[0m in \u001b[0;36m_set_ticklabels\u001b[1;34m(self, labels, fontdict, minor, **kwargs)\u001b[0m\n\u001b[0;32m   1796\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfontdict\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1797\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfontdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1798\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_ticklabels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mminor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mminor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1799\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1800\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_set_tick_locations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mticks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mminor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\axis.py\u001b[0m in \u001b[0;36mset_ticklabels\u001b[1;34m(self, ticklabels, minor, **kwargs)\u001b[0m\n\u001b[0;32m   1718\u001b[0m             \u001b[1;31m# remove all tick labels, so only error for > 0 ticklabels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1719\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlocs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mticklabels\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mticklabels\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1720\u001b[1;33m                 raise ValueError(\n\u001b[0m\u001b[0;32m   1721\u001b[0m                     \u001b[1;34m\"The number of FixedLocator locations\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1722\u001b[0m                     \u001b[1;34mf\" ({len(locator.locs)}), usually from a call to\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The number of FixedLocator locations (4), usually from a call to set_ticks, does not match the number of ticklabels (3)."
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_importances = np.zeros(X.shape[1])\n",
    "\n",
    "print('Feature importances:')\n",
    "lgb.plot_importance(grid_search.best_estimator_)\n",
    "plt.show()\n",
    "\n",
    "print('\\n' + '#' * 80)\n",
    "print('Confusion Matrix:')\n",
    "    # functions.plot_confusion_matrix(valid_y, predictions_LGB.round(), \"Analysis\",\n",
    "    #                                 index=[\"Std SSH\", \"Obf SSH\"], columns=[\"Std SSH\", \"Obf SSH\"])\n",
    "    # metrics.confusion_matrix(model, valid_features, valid_y, cmap='Blues_r')\n",
    "cm = confusion_matrix(y_test, predictions_LGB, labels=grid_search.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"video\", \"music\", \"disk\"])\n",
    "disp.plot() #cmap='Blues_r')\n",
    "plt.show()\n",
    "    \n",
    "print('\\n' + '#' * 80)\n",
    "print('Classification Report:')\n",
    "print(metrics.classification_report(y_test, grid_search.predict(X_test)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "501bb2b3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ExecutableNotFound",
     "evalue": "failed to execute WindowsPath('dot'), make sure the Graphviz executables are on your systems' PATH",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\graphviz\\backend\\execute.py\u001b[0m in \u001b[0;36mrun_check\u001b[1;34m(cmd, input_lines, encoding, quiet, **kwargs)\u001b[0m\n\u001b[0;32m     78\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'stdout'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'stderr'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m             \u001b[0mproc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_run_input_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_lines\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\graphviz\\backend\\execute.py\u001b[0m in \u001b[0;36m_run_input_lines\u001b[1;34m(cmd, input_lines, kwargs)\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_run_input_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_lines\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m     \u001b[0mpopen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstdin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask)\u001b[0m\n\u001b[0;32m    950\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 951\u001b[1;33m             self._execute_child(args, executable, preexec_fn, close_fds,\n\u001b[0m\u001b[0;32m    952\u001b[0m                                 \u001b[0mpass_fds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcwd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_gid, unused_gids, unused_uid, unused_umask, unused_start_new_session)\u001b[0m\n\u001b[0;32m   1419\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1420\u001b[1;33m                 hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n\u001b[0m\u001b[0;32m   1421\u001b[0m                                          \u001b[1;31m# no special security\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] Не удается найти указанный файл",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mExecutableNotFound\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19028\\1012161479.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot_tree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m40\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_info\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'data_percentage'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\lightgbm\\plotting.py\u001b[0m in \u001b[0;36mplot_tree\u001b[1;34m(booster, ax, tree_index, figsize, dpi, show_info, precision, orientation, example_case, **kwargs)\u001b[0m\n\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m     \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 822\u001b[1;33m     \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpipe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'png'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    823\u001b[0m     \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    824\u001b[0m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\graphviz\\piping.py\u001b[0m in \u001b[0;36mpipe\u001b[1;34m(self, format, renderer, formatter, neato_no_op, quiet, engine, encoding)\u001b[0m\n\u001b[0;32m    102\u001b[0m             \u001b[1;34m'<?xml version='\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m         \"\"\"\n\u001b[1;32m--> 104\u001b[1;33m         return self._pipe_legacy(format,\n\u001b[0m\u001b[0;32m    105\u001b[0m                                  \u001b[0mrenderer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m                                  \u001b[0mformatter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mformatter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\graphviz\\_tools.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    169\u001b[0m                               category=category)\n\u001b[0;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 171\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\graphviz\\piping.py\u001b[0m in \u001b[0;36m_pipe_legacy\u001b[1;34m(self, format, renderer, formatter, neato_no_op, quiet, engine, encoding)\u001b[0m\n\u001b[0;32m    119\u001b[0m                      \u001b[0mengine\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtyping\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m                      encoding: typing.Optional[str] = None) -> typing.Union[bytes, str]:\n\u001b[1;32m--> 121\u001b[1;33m         return self._pipe_future(format,\n\u001b[0m\u001b[0;32m    122\u001b[0m                                  \u001b[0mrenderer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m                                  \u001b[0mformatter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mformatter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\graphviz\\piping.py\u001b[0m in \u001b[0;36m_pipe_future\u001b[1;34m(self, format, renderer, formatter, neato_no_op, quiet, engine, encoding)\u001b[0m\n\u001b[0;32m    159\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mraw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 161\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pipe_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_encoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\graphviz\\backend\\piping.py\u001b[0m in \u001b[0;36mpipe_lines\u001b[1;34m(engine, format, input_lines, input_encoding, renderer, formatter, neato_no_op, quiet)\u001b[0m\n\u001b[0;32m    159\u001b[0m     \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'input_lines'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_encoding\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minput_lines\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 161\u001b[1;33m     \u001b[0mproc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecute\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_check\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcapture_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquiet\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mquiet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    162\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mproc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\graphviz\\backend\\execute.py\u001b[0m in \u001b[0;36mrun_check\u001b[1;34m(cmd, input_lines, encoding, quiet, **kwargs)\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrno\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0merrno\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mENOENT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mExecutableNotFound\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m         \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mExecutableNotFound\u001b[0m: failed to execute WindowsPath('dot'), make sure the Graphviz executables are on your systems' PATH"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 3000x4000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lgb.plot_tree(grid_search.best_estimator_, figsize=(30,40), show_info=['data_percentage',])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2f9b48",
   "metadata": {},
   "source": [
    "## Final test on X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a7ff7528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "LGB accuracy: 0.9697910447761194\n"
     ]
    }
   ],
   "source": [
    "predicted_X = grid_search.predict(X)\n",
    "print('LGB accuracy:', accuracy_score(y, predicted_X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34651452",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dea03d7e",
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: '/model_lightgbm_2.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19028\\1374319929.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mjoblib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mf'{current_path}/model_lightgbm_2.pkl'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\numpy_pickle.py\u001b[0m in \u001b[0;36mdump\u001b[1;34m(value, filename, compress, protocol, cache_size)\u001b[0m\n\u001b[0;32m    479\u001b[0m             \u001b[0mNumpyPickler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    480\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mis_filename\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 481\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    482\u001b[0m             \u001b[0mNumpyPickler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    483\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: '/model_lightgbm_2.pkl'"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(grid_search.best_estimator_, f'{current_path}/model_lightgbm_2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14247bb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
