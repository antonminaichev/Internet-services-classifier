{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b704a26c",
   "metadata": {},
   "source": [
    "## Классификация сервисов яндекс при помощи модели LigthGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30f50f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas version:  1.4.4\n",
      "lightgbm version:  4.1.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sys  \n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import (confusion_matrix, accuracy_score, ConfusionMatrixDisplay)\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "print(\"Pandas version: \", pd.__version__)\n",
    "print(\"lightgbm version: \", lgb.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4015f114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_final:  (8375, 40)\n"
     ]
    }
   ],
   "source": [
    "current_path = ''\n",
    "\n",
    "\n",
    "df_final_filename = f'data/df_final_4serv.csv'\n",
    "\n",
    "dfFinal = pd.read_csv(df_final_filename)\n",
    "\n",
    "print('df_final: ', dfFinal.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d5c70fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFinal.dropna(axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e458552b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['proto',\n",
       " 'packets_count',\n",
       " 'min_fiat',\n",
       " 'min_biat',\n",
       " 'flow_packets_per_second',\n",
       " 'f_min_pkt_size',\n",
       " 'b_min_pkt_size',\n",
       " 'diag_step_fiat',\n",
       " 'diag_step_biat',\n",
       " 'diag_steps',\n",
       " 'tcp_syn_count',\n",
       " 'tcp_rst_count',\n",
       " 'tcp_fin_count',\n",
       " 'tcp_urg_count',\n",
       " 'tcp_retr_count',\n",
       " 'pktiat_0',\n",
       " 'pktiat_1',\n",
       " 'pktiat_2',\n",
       " 'pktlen_1',\n",
       " 'type']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfFinal.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e1ac69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dfFinal['type']\n",
    "drop_col = ['type','proto','diag_step_fiat','diag_step_biat','diag_steps', 'pktiat_0', 'pktiat_1', 'pktiat_2']\n",
    "X  = dfFinal.drop(columns=drop_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb688562",
   "metadata": {},
   "source": [
    "#### Разобьем данные на подопытные и проверочные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a11ff426",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                        test_size=0.3,\n",
    "                                                        random_state=42,\n",
    "                                                        stratify=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9c45d0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['packets_count',\n",
       " 'min_fiat',\n",
       " 'min_biat',\n",
       " 'flow_packets_per_second',\n",
       " 'f_min_pkt_size',\n",
       " 'b_min_pkt_size',\n",
       " 'tcp_syn_count',\n",
       " 'tcp_rst_count',\n",
       " 'tcp_fin_count',\n",
       " 'tcp_urg_count',\n",
       " 'tcp_retr_count',\n",
       " 'pktlen_1']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ccd3a5a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "67e4eba5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fa7d87dc",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "293c8a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = lgb.LGBMClassifier(objective='multiclass', \n",
    "                               boosting_type = 'gbdt', \n",
    "                               num_class = '3',\n",
    "                               n_estimators = 1, \n",
    "                               num_trees = 1,\n",
    "                               min_child_samples = 2,\n",
    "                               class_weight = 'balanced')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b404ed0",
   "metadata": {},
   "source": [
    "##### ...со следующим набором гиперпараметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d5ad2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'max_depth': [3,4,5],\n",
    "    'num_leaves': [10,20,30],\n",
    "    'learning_rate': [0.1, 0.5, 1],\n",
    "    'feature_fraction': [0.3, 0.5, 1],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6951e2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(estimator, param_grid=parameters, scoring='accuracy', cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88bc228d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000161 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 885\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000346 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 890\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000158 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 888\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000351 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 885\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000145 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 890\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000151 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 888\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000145 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 885\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000152 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 890\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000411 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 888\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000156 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 885\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000155 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 890\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000158 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 888\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000158 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 885\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000175 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 890\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000178 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 888\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000156 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 885\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000224 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 890\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000155 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 888\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000150 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 885\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000233 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 890\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000146 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 888\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000159 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 885\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000203 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 890\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000308 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 888\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000273 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 885\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000184 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 890\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000156 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 888\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000172 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 885\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000159 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 890\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000156 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 888\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000287 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 885\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000148 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 890\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000157 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 888\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000174 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 885\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000154 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 890\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000396 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 888\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000151 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 885\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000145 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 890\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000228 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 888\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000145 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 885\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000173 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 890\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000170 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 888\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000239 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 885\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000163 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 890\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000167 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 888\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000317 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 885\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000161 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 890\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000147 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 888\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000139 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 885\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000150 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 890\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000205 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 888\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000151 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 885\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000182 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 890\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000152 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 888\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000146 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 885\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000190 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 890\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000232 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 888\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000145 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 885\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000185 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 890\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000156 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 888\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000146 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 885\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000209 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 890\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000353 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 888\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000210 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 885\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000238 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 890\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000220 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 888\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000204 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 885\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000217 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 890\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000218 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 888\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000189 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 885\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000179 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 890\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000200 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 888\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000795 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 885\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000218 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 890\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000189 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 888\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000220 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 885\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000617 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 890\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000216 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 888\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002210 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 885\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000219 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 890\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000542 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 888\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000198 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 885\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000195 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 890\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000207 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 888\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000226 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 885\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000214 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 890\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000180 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 888\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000242 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 885\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000357 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 890\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000179 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 888\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000182 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 885\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000283 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 890\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000420 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 888\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000407 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 885\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000232 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 890\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000371 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 888\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000199 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 885\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000259 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 890\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000197 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 888\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000280 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 885\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000320 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 890\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000211 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 888\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000194 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 885\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000375 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 890\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000202 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 888\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000584 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 885\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000213 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 890\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000210 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 888\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000271 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 885\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000245 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 890\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000239 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 888\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000215 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 885\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000213 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 890\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000427 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 888\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000197 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 885\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000209 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 890\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000550 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 888\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000289 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 885\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000241 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 890\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000382 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 888\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000338 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 885\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000266 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 890\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000209 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 888\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000204 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 885\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000308 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 890\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000235 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 888\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000223 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 885\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000490 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 890\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000260 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 888\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000265 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 885\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000243 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 890\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000237 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 888\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000224 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 885\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000247 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 890\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000234 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 888\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000217 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 885\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000236 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 890\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000230 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 888\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000246 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 885\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000254 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 890\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000605 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 888\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000489 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 885\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000206 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 890\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000220 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 888\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000365 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 885\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000225 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 890\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000230 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 888\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000209 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 885\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000228 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 890\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000229 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 888\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000223 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 885\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000220 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 890\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000331 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 888\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000256 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 885\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000272 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 890\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000238 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 888\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000658 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 885\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000269 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 890\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000431 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 888\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000274 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 885\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000539 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 890\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000743 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 888\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003262 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 885\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000331 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 890\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000431 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 888\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000311 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 885\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000422 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 890\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000805 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 888\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000342 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 885\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000247 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 890\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000326 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 888\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000780 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 885\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000365 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 890\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000488 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 888\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000376 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 885\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000661 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 890\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000407 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 888\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000309 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 885\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002519 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 890\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003583 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 888\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000717 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 885\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000931 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 890\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000283 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 888\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000312 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 885\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000294 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 890\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000340 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 888\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000338 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 885\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001210 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 890\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000402 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 888\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000436 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 885\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000271 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 890\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001083 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 888\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000349 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 885\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000352 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 890\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000334 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 888\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000296 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 885\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000238 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 890\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000341 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 888\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000307 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 885\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002421 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 890\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000265 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 888\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000244 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 885\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000297 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 890\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000519 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 888\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000354 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 885\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000421 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 890\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000509 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 888\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000241 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 885\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000238 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 890\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000240 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Total Bins 888\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000352 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 885\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000252 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 890\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000578 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 888\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000496 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 885\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000476 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 890\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000262 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 888\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000422 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 885\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000237 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 890\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000221 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 888\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000259 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 885\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000235 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 890\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000279 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 888\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000322 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 885\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000250 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 890\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000308 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 888\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000247 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 885\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000310 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 890\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000413 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 888\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000366 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 885\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000243 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 890\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000419 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 888\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000266 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 885\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000473 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 890\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000246 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 888\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000244 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 885\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000260 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 890\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000529 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 888\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000479 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 885\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000618 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 890\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000259 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 888\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000255 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 885\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000260 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 890\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000434 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 888\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000596 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 918\n",
      "[LightGBM] [Info] Number of data points in the train set: 5862, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=LGBMClassifier(class_weight='balanced',\n",
       "                                      min_child_samples=2, n_estimators=1,\n",
       "                                      num_class='3', num_trees=1,\n",
       "                                      objective='multiclass'),\n",
       "             param_grid={'feature_fraction': [0.3, 0.5, 1],\n",
       "                         'learning_rate': [0.1, 0.5, 1], 'max_depth': [3, 4, 5],\n",
       "                         'num_leaves': [10, 20, 30]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2bb55da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(class_weight='balanced', feature_fraction=1, max_depth=5,\n",
       "               min_child_samples=2, n_estimators=1, num_class='3',\n",
       "               num_leaves=20, num_trees=1, objective='multiclass')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9353ab07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n"
     ]
    }
   ],
   "source": [
    "predictions_LGB = grid_search.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d5458b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "0.8280939116593713\n"
     ]
    }
   ],
   "source": [
    "print(grid_search.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e8936bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importances:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "################################################################################\n",
      "Confusion Matrix:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "################################################################################\n",
      "Classification Report:\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.70      0.73       495\n",
      "           1       0.83      0.55      0.66       499\n",
      "           2       0.57      0.86      0.68       405\n",
      "           3       1.00      1.00      1.00      1114\n",
      "\n",
      "    accuracy                           0.83      2513\n",
      "   macro avg       0.79      0.78      0.77      2513\n",
      "weighted avg       0.85      0.83      0.83      2513\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feature_importances = np.zeros(X.shape[1])\n",
    "\n",
    "print('Feature importances:')\n",
    "lgb.plot_importance(grid_search.best_estimator_)\n",
    "plt.show()\n",
    "\n",
    "print('\\n' + '#' * 80)\n",
    "print('Confusion Matrix:')\n",
    "    # functions.plot_confusion_matrix(valid_y, predictions_LGB.round(), \"Analysis\",\n",
    "    #                                 index=[\"Std SSH\", \"Obf SSH\"], columns=[\"Std SSH\", \"Obf SSH\"])\n",
    "    # metrics.confusion_matrix(model, valid_features, valid_y, cmap='Blues_r')\n",
    "cm = confusion_matrix(y_test, predictions_LGB, labels=grid_search.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"video\", \"music\", \"disk\",'noserv'])\n",
    "disp.plot() #cmap='Blues_r')\n",
    "plt.show()\n",
    "    \n",
    "print('\\n' + '#' * 80)\n",
    "print('Classification Report:')\n",
    "print(metrics.classification_report(y_test, grid_search.predict(X_test)))\n",
    "plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ab8f4a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>min_fiat</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>min_biat</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>flow_packets_per_second</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>tcp_retr_count</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>b_min_pkt_size</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>packets_count</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f_min_pkt_size</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tcp_syn_count</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tcp_rst_count</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tcp_fin_count</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    feature  importance\n",
       "1                  min_fiat        15.0\n",
       "2                  min_biat        11.0\n",
       "3   flow_packets_per_second         3.5\n",
       "10           tcp_retr_count         2.0\n",
       "5            b_min_pkt_size         0.5\n",
       "0             packets_count         0.0\n",
       "4            f_min_pkt_size         0.0\n",
       "6             tcp_syn_count         0.0\n",
       "7             tcp_rst_count         0.0\n",
       "8             tcp_fin_count         0.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make sure to average feature importances! \n",
    "feature_importances = grid_search.best_estimator_.feature_importances_ / 2\n",
    "feature_importances = pd.DataFrame({'feature': list(X.columns),\n",
    "                                    'importance': feature_importances}\n",
    "                                  ).sort_values('importance', ascending = False)\n",
    "\n",
    "feature_importances.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f0cb1c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "packets_count              10.000000\n",
      "min_fiat                    0.000691\n",
      "min_biat                    0.000010\n",
      "flow_packets_per_second     1.000000\n",
      "f_min_pkt_size             66.000000\n",
      "b_min_pkt_size             66.000000\n",
      "tcp_syn_count               0.000000\n",
      "tcp_rst_count               0.000000\n",
      "tcp_fin_count               0.000000\n",
      "tcp_urg_count               0.000000\n",
      "tcp_retr_count             10.000000\n",
      "pktlen_1                   66.000000\n",
      "Name: 1, dtype: float64\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(X_train.loc[1])\n",
    "print(y_train.loc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7758d697",
   "metadata": {},
   "outputs": [
    {
     "ename": "ExecutableNotFound",
     "evalue": "failed to execute WindowsPath('dot'), make sure the Graphviz executables are on your systems' PATH",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\graphviz\\backend\\execute.py\u001b[0m in \u001b[0;36mrun_check\u001b[1;34m(cmd, input_lines, encoding, quiet, **kwargs)\u001b[0m\n\u001b[0;32m     78\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'stdout'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'stderr'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m             \u001b[0mproc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_run_input_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_lines\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\graphviz\\backend\\execute.py\u001b[0m in \u001b[0;36m_run_input_lines\u001b[1;34m(cmd, input_lines, kwargs)\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_run_input_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_lines\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m     \u001b[0mpopen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstdin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask)\u001b[0m\n\u001b[0;32m    950\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 951\u001b[1;33m             self._execute_child(args, executable, preexec_fn, close_fds,\n\u001b[0m\u001b[0;32m    952\u001b[0m                                 \u001b[0mpass_fds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcwd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_gid, unused_gids, unused_uid, unused_umask, unused_start_new_session)\u001b[0m\n\u001b[0;32m   1419\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1420\u001b[1;33m                 hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n\u001b[0m\u001b[0;32m   1421\u001b[0m                                          \u001b[1;31m# no special security\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] Не удается найти указанный файл",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mExecutableNotFound\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6488\\3541053158.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'split_gain'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'internal_value'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'internal_count'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'internal_weight'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'leaf_count'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'leaf_weight'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'data_percentage'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mlgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot_tree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtree_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m40\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_info\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mexample_case\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\lightgbm\\plotting.py\u001b[0m in \u001b[0;36mplot_tree\u001b[1;34m(booster, ax, tree_index, figsize, dpi, show_info, precision, orientation, example_case, **kwargs)\u001b[0m\n\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m     \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 822\u001b[1;33m     \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpipe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'png'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    823\u001b[0m     \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    824\u001b[0m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\graphviz\\piping.py\u001b[0m in \u001b[0;36mpipe\u001b[1;34m(self, format, renderer, formatter, neato_no_op, quiet, engine, encoding)\u001b[0m\n\u001b[0;32m    102\u001b[0m             \u001b[1;34m'<?xml version='\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m         \"\"\"\n\u001b[1;32m--> 104\u001b[1;33m         return self._pipe_legacy(format,\n\u001b[0m\u001b[0;32m    105\u001b[0m                                  \u001b[0mrenderer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m                                  \u001b[0mformatter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mformatter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\graphviz\\_tools.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    169\u001b[0m                               category=category)\n\u001b[0;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 171\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\graphviz\\piping.py\u001b[0m in \u001b[0;36m_pipe_legacy\u001b[1;34m(self, format, renderer, formatter, neato_no_op, quiet, engine, encoding)\u001b[0m\n\u001b[0;32m    119\u001b[0m                      \u001b[0mengine\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtyping\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m                      encoding: typing.Optional[str] = None) -> typing.Union[bytes, str]:\n\u001b[1;32m--> 121\u001b[1;33m         return self._pipe_future(format,\n\u001b[0m\u001b[0;32m    122\u001b[0m                                  \u001b[0mrenderer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m                                  \u001b[0mformatter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mformatter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\graphviz\\piping.py\u001b[0m in \u001b[0;36m_pipe_future\u001b[1;34m(self, format, renderer, formatter, neato_no_op, quiet, engine, encoding)\u001b[0m\n\u001b[0;32m    159\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mraw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 161\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pipe_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_encoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\graphviz\\backend\\piping.py\u001b[0m in \u001b[0;36mpipe_lines\u001b[1;34m(engine, format, input_lines, input_encoding, renderer, formatter, neato_no_op, quiet)\u001b[0m\n\u001b[0;32m    159\u001b[0m     \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'input_lines'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_encoding\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minput_lines\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 161\u001b[1;33m     \u001b[0mproc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecute\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_check\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcapture_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquiet\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mquiet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    162\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mproc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\graphviz\\backend\\execute.py\u001b[0m in \u001b[0;36mrun_check\u001b[1;34m(cmd, input_lines, encoding, quiet, **kwargs)\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrno\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0merrno\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mENOENT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mExecutableNotFound\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m         \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mExecutableNotFound\u001b[0m: failed to execute WindowsPath('dot'), make sure the Graphviz executables are on your systems' PATH"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 3000x4000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "info = ['split_gain', 'internal_value', 'internal_count', 'internal_weight', 'leaf_count', 'leaf_weight', 'data_percentage']\n",
    "lgb.plot_tree(grid_search.best_estimator_, tree_index=0, figsize=(30,40), show_info=info,example_case = X_train.loc[[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eee0e328",
   "metadata": {},
   "outputs": [
    {
     "ename": "ExecutableNotFound",
     "evalue": "failed to execute WindowsPath('dot'), make sure the Graphviz executables are on your systems' PATH",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\graphviz\\backend\\execute.py\u001b[0m in \u001b[0;36mrun_check\u001b[1;34m(cmd, input_lines, encoding, quiet, **kwargs)\u001b[0m\n\u001b[0;32m     78\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'stdout'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'stderr'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m             \u001b[0mproc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_run_input_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_lines\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\graphviz\\backend\\execute.py\u001b[0m in \u001b[0;36m_run_input_lines\u001b[1;34m(cmd, input_lines, kwargs)\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_run_input_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_lines\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m     \u001b[0mpopen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstdin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask)\u001b[0m\n\u001b[0;32m    950\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 951\u001b[1;33m             self._execute_child(args, executable, preexec_fn, close_fds,\n\u001b[0m\u001b[0;32m    952\u001b[0m                                 \u001b[0mpass_fds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcwd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_gid, unused_gids, unused_uid, unused_umask, unused_start_new_session)\u001b[0m\n\u001b[0;32m   1419\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1420\u001b[1;33m                 hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n\u001b[0m\u001b[0;32m   1421\u001b[0m                                          \u001b[1;31m# no special security\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] Не удается найти указанный файл",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mExecutableNotFound\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6488\\336374839.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot_tree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtree_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m40\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_info\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mexample_case\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\lightgbm\\plotting.py\u001b[0m in \u001b[0;36mplot_tree\u001b[1;34m(booster, ax, tree_index, figsize, dpi, show_info, precision, orientation, example_case, **kwargs)\u001b[0m\n\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m     \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 822\u001b[1;33m     \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpipe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'png'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    823\u001b[0m     \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    824\u001b[0m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\graphviz\\piping.py\u001b[0m in \u001b[0;36mpipe\u001b[1;34m(self, format, renderer, formatter, neato_no_op, quiet, engine, encoding)\u001b[0m\n\u001b[0;32m    102\u001b[0m             \u001b[1;34m'<?xml version='\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m         \"\"\"\n\u001b[1;32m--> 104\u001b[1;33m         return self._pipe_legacy(format,\n\u001b[0m\u001b[0;32m    105\u001b[0m                                  \u001b[0mrenderer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m                                  \u001b[0mformatter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mformatter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\graphviz\\_tools.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    169\u001b[0m                               category=category)\n\u001b[0;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 171\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\graphviz\\piping.py\u001b[0m in \u001b[0;36m_pipe_legacy\u001b[1;34m(self, format, renderer, formatter, neato_no_op, quiet, engine, encoding)\u001b[0m\n\u001b[0;32m    119\u001b[0m                      \u001b[0mengine\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtyping\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m                      encoding: typing.Optional[str] = None) -> typing.Union[bytes, str]:\n\u001b[1;32m--> 121\u001b[1;33m         return self._pipe_future(format,\n\u001b[0m\u001b[0;32m    122\u001b[0m                                  \u001b[0mrenderer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m                                  \u001b[0mformatter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mformatter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\graphviz\\piping.py\u001b[0m in \u001b[0;36m_pipe_future\u001b[1;34m(self, format, renderer, formatter, neato_no_op, quiet, engine, encoding)\u001b[0m\n\u001b[0;32m    159\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mraw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 161\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pipe_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_encoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\graphviz\\backend\\piping.py\u001b[0m in \u001b[0;36mpipe_lines\u001b[1;34m(engine, format, input_lines, input_encoding, renderer, formatter, neato_no_op, quiet)\u001b[0m\n\u001b[0;32m    159\u001b[0m     \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'input_lines'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_encoding\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minput_lines\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 161\u001b[1;33m     \u001b[0mproc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecute\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_check\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcapture_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquiet\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mquiet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    162\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mproc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\graphviz\\backend\\execute.py\u001b[0m in \u001b[0;36mrun_check\u001b[1;34m(cmd, input_lines, encoding, quiet, **kwargs)\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrno\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0merrno\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mENOENT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mExecutableNotFound\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m         \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mExecutableNotFound\u001b[0m: failed to execute WindowsPath('dot'), make sure the Graphviz executables are on your systems' PATH"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 3000x4000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "lgb.plot_tree(grid_search.best_estimator_, tree_index=1, figsize=(30,40), show_info=info,example_case = X_train.loc[[1]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763524f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb.plot_tree(grid_search.best_estimator_, tree_index=2, figsize=(30,40), show_info=info,example_case = X_train.loc[[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bbc33137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tree_index</th>\n",
       "      <th>node_depth</th>\n",
       "      <th>node_index</th>\n",
       "      <th>left_child</th>\n",
       "      <th>right_child</th>\n",
       "      <th>parent_index</th>\n",
       "      <th>split_feature</th>\n",
       "      <th>split_gain</th>\n",
       "      <th>threshold</th>\n",
       "      <th>decision_type</th>\n",
       "      <th>missing_direction</th>\n",
       "      <th>missing_type</th>\n",
       "      <th>value</th>\n",
       "      <th>weight</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0-S0</td>\n",
       "      <td>0-S1</td>\n",
       "      <td>0-S14</td>\n",
       "      <td>None</td>\n",
       "      <td>flow_packets_per_second</td>\n",
       "      <td>701.815002</td>\n",
       "      <td>1.000000e-35</td>\n",
       "      <td>&lt;=</td>\n",
       "      <td>left</td>\n",
       "      <td>None</td>\n",
       "      <td>-1.386290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0-S1</td>\n",
       "      <td>0-S2</td>\n",
       "      <td>0-S8</td>\n",
       "      <td>0-S0</td>\n",
       "      <td>min_fiat</td>\n",
       "      <td>511.766998</td>\n",
       "      <td>1.790047e-03</td>\n",
       "      <td>&lt;=</td>\n",
       "      <td>left</td>\n",
       "      <td>None</td>\n",
       "      <td>-1.338270</td>\n",
       "      <td>989.178000</td>\n",
       "      <td>2971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0-S2</td>\n",
       "      <td>0-S6</td>\n",
       "      <td>0-S3</td>\n",
       "      <td>0-S1</td>\n",
       "      <td>min_fiat</td>\n",
       "      <td>275.135010</td>\n",
       "      <td>2.915859e-04</td>\n",
       "      <td>&lt;=</td>\n",
       "      <td>left</td>\n",
       "      <td>None</td>\n",
       "      <td>-1.360210</td>\n",
       "      <td>904.975000</td>\n",
       "      <td>2714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0-S6</td>\n",
       "      <td>0-S10</td>\n",
       "      <td>0-S7</td>\n",
       "      <td>0-S2</td>\n",
       "      <td>min_fiat</td>\n",
       "      <td>36.895901</td>\n",
       "      <td>2.551079e-05</td>\n",
       "      <td>&lt;=</td>\n",
       "      <td>left</td>\n",
       "      <td>None</td>\n",
       "      <td>-1.414520</td>\n",
       "      <td>459.391000</td>\n",
       "      <td>1371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0-S10</td>\n",
       "      <td>0-L0</td>\n",
       "      <td>0-L11</td>\n",
       "      <td>0-S6</td>\n",
       "      <td>min_fiat</td>\n",
       "      <td>5.512870</td>\n",
       "      <td>1.442432e-05</td>\n",
       "      <td>&lt;=</td>\n",
       "      <td>left</td>\n",
       "      <td>None</td>\n",
       "      <td>-1.359830</td>\n",
       "      <td>97.261000</td>\n",
       "      <td>291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3-S1</td>\n",
       "      <td>3-L1</td>\n",
       "      <td>3-S2</td>\n",
       "      <td>3-S0</td>\n",
       "      <td>min_biat</td>\n",
       "      <td>0.995648</td>\n",
       "      <td>8.955002e-04</td>\n",
       "      <td>&lt;=</td>\n",
       "      <td>left</td>\n",
       "      <td>None</td>\n",
       "      <td>-1.486190</td>\n",
       "      <td>1099.410000</td>\n",
       "      <td>3296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3-L1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>3-S1</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-1.486294</td>\n",
       "      <td>1098.103547</td>\n",
       "      <td>3291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3-S2</td>\n",
       "      <td>3-L2</td>\n",
       "      <td>3-L3</td>\n",
       "      <td>3-S1</td>\n",
       "      <td>min_biat</td>\n",
       "      <td>3.568590</td>\n",
       "      <td>1.287246e-02</td>\n",
       "      <td>&lt;=</td>\n",
       "      <td>left</td>\n",
       "      <td>None</td>\n",
       "      <td>-1.398960</td>\n",
       "      <td>1.306830</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3-L2</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>3-S2</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-1.486294</td>\n",
       "      <td>1.021492</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3-L3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>3-S2</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-1.086294</td>\n",
       "      <td>0.285339</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>132 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     tree_index  node_depth node_index left_child right_child parent_index  \\\n",
       "0             0           1       0-S0       0-S1       0-S14         None   \n",
       "1             0           2       0-S1       0-S2        0-S8         0-S0   \n",
       "2             0           3       0-S2       0-S6        0-S3         0-S1   \n",
       "3             0           4       0-S6      0-S10        0-S7         0-S2   \n",
       "4             0           5      0-S10       0-L0       0-L11         0-S6   \n",
       "..          ...         ...        ...        ...         ...          ...   \n",
       "127           3           2       3-S1       3-L1        3-S2         3-S0   \n",
       "128           3           3       3-L1       None        None         3-S1   \n",
       "129           3           3       3-S2       3-L2        3-L3         3-S1   \n",
       "130           3           4       3-L2       None        None         3-S2   \n",
       "131           3           4       3-L3       None        None         3-S2   \n",
       "\n",
       "               split_feature  split_gain     threshold decision_type  \\\n",
       "0    flow_packets_per_second  701.815002  1.000000e-35            <=   \n",
       "1                   min_fiat  511.766998  1.790047e-03            <=   \n",
       "2                   min_fiat  275.135010  2.915859e-04            <=   \n",
       "3                   min_fiat   36.895901  2.551079e-05            <=   \n",
       "4                   min_fiat    5.512870  1.442432e-05            <=   \n",
       "..                       ...         ...           ...           ...   \n",
       "127                 min_biat    0.995648  8.955002e-04            <=   \n",
       "128                     None         NaN           NaN          None   \n",
       "129                 min_biat    3.568590  1.287246e-02            <=   \n",
       "130                     None         NaN           NaN          None   \n",
       "131                     None         NaN           NaN          None   \n",
       "\n",
       "    missing_direction missing_type     value       weight  count  \n",
       "0                left         None -1.386290     0.000000   5862  \n",
       "1                left         None -1.338270   989.178000   2971  \n",
       "2                left         None -1.360210   904.975000   2714  \n",
       "3                left         None -1.414520   459.391000   1371  \n",
       "4                left         None -1.359830    97.261000    291  \n",
       "..                ...          ...       ...          ...    ...  \n",
       "127              left         None -1.486190  1099.410000   3296  \n",
       "128              None         None -1.486294  1098.103547   3291  \n",
       "129              left         None -1.398960     1.306830      5  \n",
       "130              None         None -1.486294     1.021492      3  \n",
       "131              None         None -1.086294     0.285339      2  \n",
       "\n",
       "[132 rows x 15 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_df = grid_search.best_estimator_.booster_.trees_to_dataframe()\n",
    "print(tree_df.tree_index.max())\n",
    "grid_search.best_estimator_.booster_.trees_to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6689470b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['packets_count',\n",
       " 'min_fiat',\n",
       " 'min_biat',\n",
       " 'flow_packets_per_second',\n",
       " 'f_min_pkt_size',\n",
       " 'b_min_pkt_size',\n",
       " 'tcp_syn_count',\n",
       " 'tcp_rst_count',\n",
       " 'tcp_fin_count',\n",
       " 'tcp_urg_count',\n",
       " 'tcp_retr_count',\n",
       " 'pktlen_1']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "48f8168e",
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: '/model_lightgbm.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6488\\4055981367.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mjoblib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mf'{current_path}/model_lightgbm.pkl'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\numpy_pickle.py\u001b[0m in \u001b[0;36mdump\u001b[1;34m(value, filename, compress, protocol, cache_size)\u001b[0m\n\u001b[0;32m    479\u001b[0m             \u001b[0mNumpyPickler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    480\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mis_filename\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 481\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    482\u001b[0m             \u001b[0mNumpyPickler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    483\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: '/model_lightgbm.pkl'"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(grid_search.best_estimator_, f'{current_path}/model_lightgbm.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7ebc9f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000199 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 918\n",
      "[LightGBM] [Info] Number of data points in the train set: 5862, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000166 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 910\n",
      "[LightGBM] [Info] Number of data points in the train set: 5862, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000178 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 887\n",
      "[LightGBM] [Info] Number of data points in the train set: 5862, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000157 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 884\n",
      "[LightGBM] [Info] Number of data points in the train set: 5862, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000050 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 880\n",
      "[LightGBM] [Info] Number of data points in the train set: 5862, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000044 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 874\n",
      "[LightGBM] [Info] Number of data points in the train set: 5862, number of used features: 6\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000138 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 874\n",
      "[LightGBM] [Info] Number of data points in the train set: 5862, number of used features: 6\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000166 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 795\n",
      "[LightGBM] [Info] Number of data points in the train set: 5862, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] num_iterations is set=1, num_trees=1 will be ignored. Current value: num_iterations=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000122 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 773\n",
      "[LightGBM] [Info] Number of data points in the train set: 5862, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "model_for_rfe = grid_search.best_estimator_\n",
    "\n",
    "rfe = RFE(model_for_rfe, n_features_to_select=4, step=1)\n",
    "X_train_rfe = X_train\n",
    "y_train_rfe = y_train\n",
    "fit = rfe.fit(X_train_rfe,y_train_rfe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "68abd669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Число признаков: 4\n",
      "Отобранные признаки: [False  True  True  True False False False False False False  True False]\n",
      "Ранг признаков: [9 1 1 1 8 2 7 6 5 4 1 3]\n"
     ]
    }
   ],
   "source": [
    "print((\"Число признаков: %d\") %fit.n_features_)\n",
    "print((\"Отобранные признаки: %s\") %fit.support_)\n",
    "print((\"Ранг признаков: %s\") %fit.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e140410c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['min_fiat' 'min_biat' 'flow_packets_per_second' 'tcp_retr_count']\n"
     ]
    }
   ],
   "source": [
    "feature_names_rfe = fit.get_feature_names_out()\n",
    "print(feature_names_rfe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6848c56d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b3c113c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "0.8280939116593713\n"
     ]
    }
   ],
   "source": [
    "print(fit.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fed3da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eaee3ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFinal_new = dfFinal[feature_names_rfe]\n",
    "y = dfFinal['type']\n",
    "\n",
    "X  = dfFinal_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed15cef",
   "metadata": {},
   "source": [
    "#### Разобьем данные на подопытные и проверочные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f935779b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                        test_size=0.3,\n",
    "                                                        random_state=42,\n",
    "                                                        stratify=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ab769363",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8375, 4)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24c45a8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3abc2a18",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c73abc48",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0d88a248",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = lgb.LGBMClassifier(objective='multiclass', \n",
    "                               boosting_type = 'gbdt', \n",
    "                               num_class = '3',\n",
    "                               n_estimators = 100, \n",
    "                               class_weight = 'balanced')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4321452f",
   "metadata": {},
   "source": [
    "##### ...со следующим набором гиперпараметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7f2da23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'max_depth': [4],\n",
    "    'num_leaves': [20],\n",
    "    'min_child_samples': [19],\n",
    "    'min_child_weight': [0.002],\n",
    "    'feature_fraction': [0.6],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2b5f3014",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(estimator, param_grid=parameters, scoring='accuracy', cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "35fb8c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000121 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 773\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000098 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 772\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000133 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 773\n",
      "[LightGBM] [Info] Number of data points in the train set: 3908, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000144 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 773\n",
      "[LightGBM] [Info] Number of data points in the train set: 5862, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=LGBMClassifier(class_weight='balanced', num_class='3',\n",
       "                                      objective='multiclass'),\n",
       "             param_grid={'feature_fraction': [0.6], 'max_depth': [4],\n",
       "                         'min_child_samples': [19], 'min_child_weight': [0.002],\n",
       "                         'num_leaves': [20]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f838882a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(class_weight='balanced', feature_fraction=0.6, max_depth=4,\n",
       "               min_child_samples=19, min_child_weight=0.002, num_class='3',\n",
       "               num_leaves=20, objective='multiclass')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3fa4800a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "0.838042180660565\n"
     ]
    }
   ],
   "source": [
    "predictions_LGB = grid_search.predict(X_test)\n",
    "print(grid_search.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7f22bb5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importances:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "################################################################################\n",
      "Confusion Matrix:\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The number of FixedLocator locations (4), usually from a call to set_ticks, does not match the number of ticklabels (3).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6488\\669805817.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mcm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictions_LGB\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mdisp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mConfusionMatrixDisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdisplay_labels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"video\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"music\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"disk\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mdisp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#cmap='Blues_r')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_plot\\confusion_matrix.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(self, include_values, cmap, xticks_rotation, values_format, ax, colorbar)\u001b[0m\n\u001b[0;32m    161\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcolorbar\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m             \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolorbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mim_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m         ax.set(\n\u001b[0m\u001b[0;32m    164\u001b[0m             \u001b[0mxticks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m             \u001b[0myticks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\artist.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    114\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m         \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mArtist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m         \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"set\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__qualname__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf\"{cls.__qualname__}.set\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\artist.py\u001b[0m in \u001b[0;36mset\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m   1162\u001b[0m         \u001b[1;31m# module.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1163\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1164\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1165\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1166\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mcontextlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontextmanager\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\artist.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, props)\u001b[0m\n\u001b[0;32m   1064\u001b[0m                         raise AttributeError(f\"{type(self).__name__!r} object \"\n\u001b[0;32m   1065\u001b[0m                                              f\"has no property {k!r}\")\n\u001b[1;32m-> 1066\u001b[1;33m                     \u001b[0mret\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1067\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1068\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpchanged\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mget_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mowner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__module__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\axis.py\u001b[0m in \u001b[0;36m_set_ticklabels\u001b[1;34m(self, labels, fontdict, minor, **kwargs)\u001b[0m\n\u001b[0;32m   1796\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfontdict\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1797\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfontdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1798\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_ticklabels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mminor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mminor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1799\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1800\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_set_tick_locations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mticks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mminor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\axis.py\u001b[0m in \u001b[0;36mset_ticklabels\u001b[1;34m(self, ticklabels, minor, **kwargs)\u001b[0m\n\u001b[0;32m   1718\u001b[0m             \u001b[1;31m# remove all tick labels, so only error for > 0 ticklabels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1719\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlocs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mticklabels\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mticklabels\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1720\u001b[1;33m                 raise ValueError(\n\u001b[0m\u001b[0;32m   1721\u001b[0m                     \u001b[1;34m\"The number of FixedLocator locations\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1722\u001b[0m                     \u001b[1;34mf\" ({len(locator.locs)}), usually from a call to\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The number of FixedLocator locations (4), usually from a call to set_ticks, does not match the number of ticklabels (3)."
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_importances = np.zeros(X.shape[1])\n",
    "\n",
    "print('Feature importances:')\n",
    "lgb.plot_importance(grid_search.best_estimator_)\n",
    "plt.show()\n",
    "\n",
    "print('\\n' + '#' * 80)\n",
    "print('Confusion Matrix:')\n",
    "    # functions.plot_confusion_matrix(valid_y, predictions_LGB.round(), \"Analysis\",\n",
    "    #                                 index=[\"Std SSH\", \"Obf SSH\"], columns=[\"Std SSH\", \"Obf SSH\"])\n",
    "    # metrics.confusion_matrix(model, valid_features, valid_y, cmap='Blues_r')\n",
    "cm = confusion_matrix(y_test, predictions_LGB, labels=grid_search.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"video\", \"music\", \"disk\"])\n",
    "disp.plot() #cmap='Blues_r')\n",
    "plt.show()\n",
    "    \n",
    "print('\\n' + '#' * 80)\n",
    "print('Classification Report:')\n",
    "print(metrics.classification_report(y_test, grid_search.predict(X_test)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501bb2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb.plot_tree(grid_search.best_estimator_, figsize=(30,40), show_info=['data_percentage',])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2f9b48",
   "metadata": {},
   "source": [
    "## Final test on X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a7ff7528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "LGB accuracy: 0.8416716417910448\n"
     ]
    }
   ],
   "source": [
    "predicted_X = grid_search.predict(X)\n",
    "print('LGB accuracy:', accuracy_score(y, predicted_X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34651452",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea03d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(grid_search.best_estimator_, f'{current_path}/model_lightgbm_2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27adf3ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
